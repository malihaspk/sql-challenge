# sql-challenge
## Background
 In this Challenge we have been asked to do a research project about people whom the company employed during the 1980s and 1990s, from the employee database that consist of six CSV files.

## Objectives
 We need to design the tables to hold the data from the CSV files, import the CSV files into a SQL database, and then answer questions about the data. 
 
 Project is divided into three parts
  
  1.Data Modeling 
  2.Data Engineering
  3.Data Analysis

## Data Modeling
 After inspecting the CSV files, an Entity Relationship Diagram of the tables has been
created by using QuickDBD tool. The image file has been provided in repository.

## Data Engineering
  A table schema for each of the 6 CSV files with specific data types, primary keys, foreign keys, and constraints has been created in pgAdmin. In the Schema 6 tables can be seen against 6 six files. After creating the tables and providing the relevant column details with data types, Primary Keys and Foreign Keys, the data has been imported into the corresponding tables. The schema file can be found in repository with the name SQL_SCHEMA.

## Data Analysis
 Once the Data Modelling and Data Engineering are completed successfully, its the time for Data Analysis.
 To conduct Data Analysis there are several queries that has been asked by using table join, group by, conditionals, wildcards and orderby.  
 A detailed Data analysis is provided in the repository in the file SQL_Analysis.

## References
For ERD QuickDB Design Tool has been used and the link has been provided.
https://www.quickdatabasediagrams.com/

For Data Engineering and Data Analysis 'pgAdmin' has been used.
 


